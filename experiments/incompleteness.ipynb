{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying neighbourhood fingerprints: counterexamples from [Pozdnyakov et al., 2020](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.125.166001)\n",
    "\n",
    "*Background:*\n",
    "Geometric GNNs identify local neighbourhoods around nodes via **'neighbourhood finderprints'** or scalarisations, where local geometric information from subsets of neighbours is aggregated to compute invariant scalars. The number of neighbours involved in computing the scalars is termed the **body order**.\n",
    "The ideal neighbourhood fingerprint would perfectly identify neighbourhoods, which requires arbitrarily high body order.\n",
    "\n",
    "*Experiment:*\n",
    "To demonstrate the practical implications of scalarisation body order, we evaluate geometric GNN layers on their ability to discriminate counterexamples from [Pozdnyakov et al., 2020](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.125.166001).\n",
    "Each counterexample consists of a pair of local neighbourhoods that are **indistinguishable** when comparing their set of $k$-body scalars, i.e. geometric GNN layers with body order $k$ cannot distinguish the neighbourhoods.\n",
    "The 3-body counterexample corresponds to Fig.1(b) in Pozdnyakov et al., 2020, 4-body chiral to Fig.2(e), and 4-body non-chiral to Fig.2(f); the 2-body counterexample is based on the two local neighbourhoods in our running example.\n",
    "In this notebook, we train single layer geometric GNNs to distinguish the counterexamples using updated scalar features. \n",
    "\n",
    "![Counterexamples from Pozdnyakov et al., 2020](fig/incompleteness.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 1.13.1\n",
      "PyG version 2.0.3\n",
      "e3nn version 0.5.1\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import is_undirected, to_undirected, remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "import e3nn\n",
    "from e3nn import o3\n",
    "from functools import partial\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))\n",
    "print(\"e3nn version {}\".format(e3nn.__version__))\n",
    "\n",
    "from src.utils.plot_utils import plot_2d, plot_3d\n",
    "from src.utils.train_utils import run_experiment\n",
    "from src.models import MPNNModel, EGNNModel, GVPGNNModel, TFNModel, SchNetModel, DimeNetPPModel, MACEModel\n",
    "from cartesian_mace.models.model import CartesianMACE\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "# print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "# print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-body counterexample\n",
    "\n",
    "Pair of local neighbourhoods that are indistinguishable when comparing their set of $2$-body scalars, i.e. the unordered set of pairwise distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_two_body_envs():\n",
    "    dataset = []\n",
    "\n",
    "\n",
    "    # Environment 0\n",
    "    # atoms = torch.LongTensor([ 0, 1, 2 ])\n",
    "    atoms = torch.LongTensor([ 0, 0, 0 ])\n",
    "    edge_index = torch.LongTensor([ [0, 0], [1, 2] ])\n",
    "    pos = torch.FloatTensor([ \n",
    "        [0, 0, 0],\n",
    "        [5, 0, 0],\n",
    "        [3, 0, 4]\n",
    "    ])\n",
    "    y = torch.LongTensor([0])  # Label 0\n",
    "    data1 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y, batch=atoms)\n",
    "    data1.edge_index = to_undirected(data1.edge_index)\n",
    "    dataset.append(data1)\n",
    "    \n",
    "    # Environment 1\n",
    "    # atoms = torch.LongTensor([ 0, 1, 2 ])\n",
    "    atoms = torch.LongTensor([ 0, 0, 0 ])\n",
    "    edge_index = torch.LongTensor([ [0, 0], [1, 2] ])\n",
    "    pos = torch.FloatTensor([ \n",
    "        [0, 0, 0],\n",
    "        [5, 0, 0],\n",
    "        [-5, 0, 0]\n",
    "    ])\n",
    "    y = torch.LongTensor([1])  # Label 1\n",
    "    data2 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y, batch=atoms)\n",
    "    data2.edge_index = to_undirected(data2.edge_index)\n",
    "    dataset.append(data2)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = create_two_body_envs()\n",
    "# for data in dataset:\n",
    "#     plot_3d(data, lim=5)\n",
    "\n",
    "# Set model\n",
    "model_name = \"cmace\"\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "num_layers = 1\n",
    "correlation = 2\n",
    "max_ell = 2\n",
    "model = {\n",
    "    \"mpnn\": MPNNModel,\n",
    "    \"schnet\": SchNetModel,\n",
    "    \"dimenet\": DimeNetPPModel,\n",
    "#     \"egnn\": EGNNModel,\n",
    "    \"gvp\": GVPGNNModel,\n",
    "    \"tfn\": TFNModel,\n",
    "    \"cmace\": partial(CartesianMACE, self_tp_rank_max=max_ell, basis_rank_max=max_ell, feature_rank_max=max_ell, nu_max=correlation),\n",
    "    \"mace\": partial(MACEModel, correlation=correlation),\n",
    "}[model_name](num_layers=num_layers, in_dim=1, out_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6210, -0.0443]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.6490, -0.0315]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset:\n",
    "    print(model(batch))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " val[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "\n",
      "test[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    model,\n",
    "    dataloader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=10,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three-body counterexample\n",
    "\n",
    "Pair of local neighbourhoods that are indistinguishable when comparing their set of $3$-body scalars, i.e. the unordered set of pairwise distances as well as angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_three_body_envs():\n",
    "    dataset = []\n",
    "\n",
    "    a_x, a_y, a_z = 5, 0, 5\n",
    "    b_x, b_y, b_z = 5, 5, 5\n",
    "    c_x, c_y, c_z = 0, 5, 5\n",
    "    \n",
    "    # Environment 0\n",
    "    # atoms = torch.LongTensor([ 0, 1, 2, 3, 4 ])\n",
    "    atoms = torch.LongTensor([ 0, 0, 0, 0, 0 ])\n",
    "    edge_index = torch.LongTensor([ [0, 0, 0, 0], [1, 2, 3, 4] ])\n",
    "    pos = torch.FloatTensor([ \n",
    "        [0, 0, 0],\n",
    "        [a_x, a_y, a_z],\n",
    "        [+b_x, +b_y, b_z],\n",
    "        [-b_x, -b_y, b_z],\n",
    "        [c_x, +c_y, c_z],\n",
    "    ])\n",
    "    y = torch.LongTensor([0])  # Label 0\n",
    "    data1 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y, batch=atoms)\n",
    "    data1.edge_index = to_undirected(data1.edge_index)\n",
    "    dataset.append(data1)\n",
    "    \n",
    "    # Environment 1\n",
    "    # atoms = torch.LongTensor([ 0, 1, 2, 3, 4 ])\n",
    "    atoms = torch.LongTensor([ 0, 0, 0, 0, 0 ])\n",
    "    edge_index = torch.LongTensor([ [0, 0, 0, 0], [1, 2, 3, 4] ])\n",
    "    pos = torch.FloatTensor([ \n",
    "        [0, 0, 0],\n",
    "        [a_x, a_y, a_z],\n",
    "        [+b_x, +b_y, b_z],\n",
    "        [-b_x, -b_y, b_z],\n",
    "        [c_x, -c_y, c_z],\n",
    "    ])\n",
    "    y = torch.LongTensor([1])  # Label 1\n",
    "    data2 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y, batch=atoms)\n",
    "    data2.edge_index = to_undirected(data2.edge_index)\n",
    "    dataset.append(data2)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0148, -0.0780]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0044, -0.0749]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "dataset = create_three_body_envs()\n",
    "# for data in dataset:\n",
    "#     plot_3d(data, lim=5)\n",
    "\n",
    "# Set model\n",
    "model_name = \"cmace\"\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "max_ell=2\n",
    "num_layers = 1\n",
    "correlation = 2\n",
    "model = {\n",
    "    \"mpnn\": MPNNModel,\n",
    "    \"schnet\": SchNetModel,\n",
    "    \"dimenet\": DimeNetPPModel,\n",
    "    \"egnn\": EGNNModel,\n",
    "    \"gvp\": GVPGNNModel,\n",
    "    \"tfn\": TFNModel,\n",
    "     \"cmace\": partial(CartesianMACE, self_tp_rank_max=max_ell, basis_rank_max=max_ell, feature_rank_max=max_ell, nu_max=correlation),\n",
    "    \"mace\": partial(MACEModel, correlation=correlation),\n",
    "}[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
    "\n",
    "for batch in dataset:\n",
    "    print(model(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "CartesianMACE(\n  (emb_in): Embedding(1, 1)\n  (create_atomic_bases): ModuleList(\n    (0): AtomicBasis(\n      (contractions): ModuleDict(\n        (00:0): CartesianContraction()\n        (01:1): CartesianContraction()\n        (02:0): CartesianContraction()\n        (02:2): CartesianContraction()\n      )\n    )\n  )\n  (weighted_sums): ModuleList(\n    (0): WeightedSum(\n      (contractions): ModuleDict(\n        (0:0): CartesianContraction()\n        (1:1): CartesianContraction()\n        (2:0): CartesianContraction()\n        (2:2): CartesianContraction()\n        (00:0): CartesianContraction()\n        (01:1): CartesianContraction()\n        (02:0): CartesianContraction()\n        (02:2): CartesianContraction()\n        (11:0): CartesianContraction()\n        (11:2): CartesianContraction()\n        (12:1): CartesianContraction()\n        (22:0): CartesianContraction()\n        (22:2): CartesianContraction()\n        (000:0): CartesianContraction()\n        (001:1): CartesianContraction()\n        (002:0): CartesianContraction()\n        (002:2): CartesianContraction()\n        (011:0): CartesianContraction()\n        (011:2): CartesianContraction()\n        (012:1): CartesianContraction()\n        (111:1): CartesianContraction()\n        (022:0): CartesianContraction()\n        (022:2): CartesianContraction()\n        (112:0): CartesianContraction()\n        (112:2): CartesianContraction()\n        (122:1): CartesianContraction()\n        (222:0): CartesianContraction()\n        (222:2): CartesianContraction()\n      )\n      (channel_mixing): ParameterDict(\n          (0): Parameter containing: [torch.FloatTensor of size 1x1x1]\n          (1): Parameter containing: [torch.FloatTensor of size 1x1x1]\n          (2): Parameter containing: [torch.FloatTensor of size 1x1x1]\n          (00): Parameter containing: [torch.FloatTensor of size 2x1x1]\n          (01): Parameter containing: [torch.FloatTensor of size 2x1x1]\n          (02): Parameter containing: [torch.FloatTensor of size 2x1x1]\n          (11): Parameter containing: [torch.FloatTensor of size 2x1x1]\n          (12): Parameter containing: [torch.FloatTensor of size 2x1x1]\n          (22): Parameter containing: [torch.FloatTensor of size 2x1x1]\n          (000): Parameter containing: [torch.FloatTensor of size 3x1x1]\n          (001): Parameter containing: [torch.FloatTensor of size 3x1x1]\n          (002): Parameter containing: [torch.FloatTensor of size 3x1x1]\n          (011): Parameter containing: [torch.FloatTensor of size 3x1x1]\n          (012): Parameter containing: [torch.FloatTensor of size 3x1x1]\n          (111): Parameter containing: [torch.FloatTensor of size 3x1x1]\n          (022): Parameter containing: [torch.FloatTensor of size 3x1x1]\n          (112): Parameter containing: [torch.FloatTensor of size 3x1x1]\n          (122): Parameter containing: [torch.FloatTensor of size 3x1x1]\n          (222): Parameter containing: [torch.FloatTensor of size 3x1x1]\n      )\n    )\n  )\n  (channel_weights): ParameterList(  (0): Parameter containing: [torch.float32 of size 3x1x1])\n  (message_weights): ParameterList(  (0): Parameter containing: [torch.float32 of size 3x1x1])\n  (pred): Linear(in_features=13, out_features=2, bias=True)\n)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for CartesianMACE (cpu).\n",
      "50.0\n",
      "50.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "\n",
      " val[50.0, 50.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "\n",
      "test[50.0, 50.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    model,\n",
    "    dataloader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=10,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four-body non-chiral counterexample\n",
    "\n",
    "Pair of local neighbourhoods that are indistinguishable when comparing their set of $4$-body scalars without considering chirality/handedness, i.e. the unordered set of pairwise distances, angles, and quadruplet scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_four_body_nonchiral_envs():\n",
    "    dataset = []\n",
    "\n",
    "    a1_x, a1_y, a1_z = 3, 2, -4\n",
    "    a2_x, a2_y, a2_z = 0, 2, 5\n",
    "    a3_x, a3_y, a3_z = -3, 2, -4\n",
    "    b1_x, b1_y, b1_z = 3, -2, -4\n",
    "    b2_x, b2_y, b2_z = 0, -2, 5\n",
    "    b3_x, b3_y, b3_z = -3, -2, -4\n",
    "    c_x, c_y, c_z = 0, 5, 0\n",
    "\n",
    "    angle = 2 * torch.pi / 10 # random angle\n",
    "    Q = o3.matrix_y(torch.tensor(angle)).numpy()\n",
    "\n",
    "    # Environment 0\n",
    "    # atoms = torch.LongTensor([ 0, 1, 1, 1, 1, 1, 1, 2 ])\n",
    "    atoms = torch.LongTensor([ 0, 0, 0, 0, 0, 0, 0, 0 ])\n",
    "    edge_index = torch.LongTensor([ [0, 0, 0, 0, 0, 0, 0], [1, 2, 3, 4, 5, 6, 7] ])\n",
    "    pos = torch.FloatTensor([ \n",
    "        [0, 0, 0],\n",
    "        [a1_x, a1_y, a1_z],\n",
    "        [a2_x, a2_y, a2_z],\n",
    "        [a3_x, a3_y, a3_z],\n",
    "        [b1_x, b1_y, b1_z] @ Q,\n",
    "        [b2_x, b2_y, b2_z] @ Q,\n",
    "        [b3_x, b3_y, b3_z] @ Q,\n",
    "        [c_x, +c_y, c_z],\n",
    "    ])\n",
    "    y = torch.LongTensor([0])  # Label 0\n",
    "    data1 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y)\n",
    "    data1.edge_index = to_undirected(data1.edge_index)\n",
    "    dataset.append(data1)\n",
    "    \n",
    "    # Environment 1\n",
    "    # atoms = torch.LongTensor([ 0, 1, 1, 1, 1, 1, 1, 2 ])\n",
    "    atoms = torch.LongTensor([ 0, 0, 0, 0, 0, 0, 0, 0 ])\n",
    "    edge_index = torch.LongTensor([ [0, 0, 0, 0, 0, 0, 0], [1, 2, 3, 4, 5, 6, 7] ])\n",
    "    pos = torch.FloatTensor([ \n",
    "        [0, 0, 0],\n",
    "        [a1_x, a1_y, a1_z],\n",
    "        [a2_x, a2_y, a2_z],\n",
    "        [a3_x, a3_y, a3_z],\n",
    "        [b1_x, b1_y, b1_z] @ Q,\n",
    "        [b2_x, b2_y, b2_z] @ Q,\n",
    "        [b3_x, b3_y, b3_z] @ Q,\n",
    "        [c_x, -c_y, c_z],\n",
    "    ])\n",
    "    y = torch.LongTensor([1])  # Label 1\n",
    "    data2 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y)\n",
    "    data2.edge_index = to_undirected(data2.edge_index)\n",
    "    dataset.append(data2)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = create_four_body_nonchiral_envs()\n",
    "# for data in dataset:\n",
    "#     plot_3d(data, lim=5)\n",
    "\n",
    "# Set model\n",
    "model_name = \"cmace\"\n",
    "max_ell=1\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "num_layers = 1\n",
    "correlation = 4\n",
    "model = {\n",
    "    \"mpnn\": MPNNModel,\n",
    "    \"schnet\": SchNetModel,\n",
    "    \"dimenet\": DimeNetPPModel,\n",
    "    \"egnn\": EGNNModel,\n",
    "    \"gvp\": GVPGNNModel,\n",
    "    \"tfn\": TFNModel,\n",
    "    \"cmace\": partial(CartesianMACE, self_tp_rank_max=max_ell, basis_rank_max=max_ell, feature_rank_max=max_ell, nu_max=correlation),\n",
    "    \"mace\": partial(MACEModel, max_ell=3, correlation=correlation),\n",
    "}[model_name](num_layers=num_layers, in_dim=1, out_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:22<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " val[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "\n",
      "test[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    model,\n",
    "    dataloader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=10,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four-body chiral counterexample\n",
    "\n",
    "Pair of local neighbourhoods that are indistinguishable when comparing their set of $4$-body scalars when considering chirality/handedness, i.e. the unordered set of pairwise distances, angles, and quadruplet scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_four_body_chiral_envs():\n",
    "    dataset = []\n",
    "\n",
    "    a1_x, a1_y, a1_z = 3, 0, -4\n",
    "    a2_x, a2_y, a2_z = 0, 0, 5\n",
    "    a3_x, a3_y, a3_z = -3, 0, -4\n",
    "    c_x, c_y, c_z = 0, 5, 0\n",
    "\n",
    "    # Environment 0\n",
    "    # atoms = torch.LongTensor([ 0, 1, 1, 1, 2 ])\n",
    "    atoms = torch.LongTensor([ 0, 0, 0, 0, 0 ])\n",
    "    edge_index = torch.LongTensor([ [0, 0, 0, 0], [1, 2, 3, 4] ])\n",
    "    pos = torch.FloatTensor([ \n",
    "        [0, 0, 0],\n",
    "        [a1_x, a1_y, a1_z],\n",
    "        [a2_x, a2_y, a2_z],\n",
    "        [a3_x, a3_y, a3_z],\n",
    "        [c_x, +c_y, c_z],\n",
    "    ])\n",
    "    y = torch.LongTensor([0])  # Label 0\n",
    "    data1 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y)\n",
    "    data1.edge_index = to_undirected(data1.edge_index)\n",
    "    dataset.append(data1)\n",
    "    \n",
    "    # Environment 1\n",
    "    # atoms = torch.LongTensor([ 0, 1, 1, 1, 2 ])\n",
    "    atoms = torch.LongTensor([ 0, 0, 0, 0, 0 ])\n",
    "    edge_index = torch.LongTensor([ [0, 0, 0, 0], [1, 2, 3, 4] ])\n",
    "    pos = torch.FloatTensor([ \n",
    "        [0, 0, 0],\n",
    "        [a1_x, a1_y, a1_z],\n",
    "        [a2_x, a2_y, a2_z],\n",
    "        [a3_x, a3_y, a3_z],\n",
    "        [c_x, -c_y, c_z],\n",
    "    ])\n",
    "    y = torch.LongTensor([1])  # Label 1\n",
    "    data2 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y)\n",
    "    data2.edge_index = to_undirected(data2.edge_index)\n",
    "    dataset.append(data2)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_four_body_chiral_envs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[61], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Create dataset\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_four_body_chiral_envs\u001B[49m()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# for data in dataset:\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#     plot_3d(data, lim=5)\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Set model\u001B[39;00m\n\u001B[1;32m      7\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmace\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'create_four_body_chiral_envs' is not defined"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "dataset = create_four_body_chiral_envs()\n",
    "# for data in dataset:\n",
    "#     plot_3d(data, lim=5)\n",
    "\n",
    "# Set model\n",
    "model_name = \"mace\"\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "num_layers = 1\n",
    "correlation = 4\n",
    "model = {\n",
    "    \"mpnn\": MPNNModel,\n",
    "    \"schnet\": SchNetModel,\n",
    "    \"dimenet\": DimeNetPPModel,\n",
    "    \"egnn\": EGNNModel,\n",
    "    \"gvp\": GVPGNNModel,\n",
    "    \"tfn\": TFNModel,\n",
    "    \"mace\": partial(MACEModel, correlation=correlation),\n",
    "}[model_name](num_layers=num_layers, in_dim=1, out_dim=2)\n",
    "\n",
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    model, \n",
    "    dataloader,\n",
    "    val_loader, \n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=10,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def create_cmace(correlation:int, max_ell:int):\n",
    "    return CartesianMACE(\n",
    "        self_tp_rank_max=max_ell,\n",
    "        basis_rank_max=max_ell,\n",
    "        feature_rank_max=max_ell,\n",
    "        nu_max=correlation,\n",
    "        num_layers=1,\n",
    "        in_dim=1,\n",
    "        out_dim=2,\n",
    "        scalar_pred=True\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Two-body envs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "dataset = create_two_body_envs()\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "three_body = create_cmace(correlation=2, max_ell=2)\n",
    "four_body = create_cmace(correlation=3, max_ell=2)\n",
    "five_body = create_cmace(correlation=4, max_ell=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:04<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " val[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "\n",
      "test[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    three_body,\n",
    "    dataloader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=10,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " val[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "\n",
      "test[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    four_body,\n",
    "    dataloader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=10,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for CartesianMACE (cpu).\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "100.0\n",
      "\n",
      " val[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "\n",
      "test[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n"
     ]
    }
   ],
   "source": [
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    five_body,\n",
    "    dataloader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=10,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Three-body envs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "dataset = create_three_body_envs()\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "three_body = create_cmace(correlation=2, max_ell=2)\n",
    "four_body = create_cmace(correlation=3, max_ell=2)\n",
    "five_body = create_cmace(correlation=4, max_ell=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for CartesianMACE (cpu).\n",
      "50.0\n",
      "50.0\n",
      "50.0\n",
      "50.0\n",
      "50.0\n",
      "50.0\n",
      "50.0\n",
      "50.0\n",
      "50.0\n",
      "50.0\n",
      "\n",
      " val[50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0]\n",
      "\n",
      "test[50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0]\n"
     ]
    }
   ],
   "source": [
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    three_body,\n",
    "    dataloader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=10,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4987,  1.9662]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.4987,  1.9662]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "four_body = create_cmace(correlation=3, max_ell=2)\n",
    "for batch in dataset:\n",
    "\n",
    "    print(four_body(batch))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[66], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m best_val_acc, test_acc, train_time \u001B[38;5;241m=\u001B[39m \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfour_body\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_times\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/geometric-gnn-dojo/src/utils/train_utils.py:107\u001B[0m, in \u001B[0;36mrun_experiment\u001B[0;34m(model, train_loader, val_loader, test_loader, n_epochs, n_times, verbose, device)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_times):\n\u001B[1;32m    106\u001B[0m     seed(idx) \u001B[38;5;66;03m# set random seed\u001B[39;00m\n\u001B[0;32m--> 107\u001B[0m     best_val_acc, test_acc, train_time, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_run_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    108\u001B[0m     best_val_acc_list\u001B[38;5;241m.\u001B[39mappend(best_val_acc)\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28mprint\u001B[39m(test_acc)\n",
      "File \u001B[0;32m~/PycharmProjects/geometric-gnn-dojo/src/utils/train_utils.py:73\u001B[0m, in \u001B[0;36m_run_experiment\u001B[0;34m(model, train_loader, val_loader, test_loader, n_epochs, verbose, device)\u001B[0m\n\u001B[1;32m     70\u001B[0m t \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_epochs\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;66;03m# Train model for one epoch, return avg. training loss\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;66;03m# Evaluate model on validation set\u001B[39;00m\n\u001B[1;32m     76\u001B[0m     val_acc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28meval\u001B[39m(model, val_loader, device)\n",
      "File \u001B[0;32m~/PycharmProjects/geometric-gnn-dojo/src/utils/train_utils.py:30\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train_loader, optimizer, device)\u001B[0m\n\u001B[1;32m     28\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model(batch)\n\u001B[1;32m     29\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mcross_entropy(y_pred, batch\u001B[38;5;241m.\u001B[39my)\n\u001B[0;32m---> 30\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m loss_all \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m*\u001B[39m batch\u001B[38;5;241m.\u001B[39mnum_graphs\n\u001B[1;32m     32\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/PycharmProjects/geometric-gnn-dojo/venv/lib/python3.9/site-packages/torch/_tensor.py:488\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    479\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    480\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    481\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    486\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    487\u001B[0m     )\n\u001B[0;32m--> 488\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/geometric-gnn-dojo/venv/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    192\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    194\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    four_body,\n",
    "    dataloader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=30,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0413, -3.0395]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.0498, -3.0466]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset:\n",
    "    print(four_body(batch))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for batch in dataset:\n",
    "    print(four_body(batch))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_experiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m best_val_acc, test_acc, train_time \u001B[38;5;241m=\u001B[39m \u001B[43mrun_experiment\u001B[49m(\n\u001B[1;32m      2\u001B[0m     five_body,\n\u001B[1;32m      3\u001B[0m     dataloader,\n\u001B[1;32m      4\u001B[0m     val_loader,\n\u001B[1;32m      5\u001B[0m     test_loader,\n\u001B[1;32m      6\u001B[0m     n_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[1;32m      7\u001B[0m     n_times\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,\n\u001B[1;32m      8\u001B[0m     device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[1;32m      9\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     10\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'run_experiment' is not defined"
     ]
    }
   ],
   "source": [
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    five_body,\n",
    "    dataloader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=100,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Four-body envs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "dataset = create_four_body_nonchiral_envs()\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "three_body = create_cmace(correlation=2, max_ell=1)\n",
    "four_body = create_cmace(correlation=3, max_ell=1)\n",
    "five_body = create_cmace(correlation=4, max_ell=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "94aa676993820a604ac86f7af94f5432e989a749d5dd43e18f9507de2e8c2897"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
