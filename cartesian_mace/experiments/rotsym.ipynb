{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "PyTorch version 1.13.1\n",
      "PyG version 2.0.3\n",
      "e3nn version 0.5.1\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import is_undirected, to_undirected, remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "import e3nn\n",
    "from e3nn import o3\n",
    "from functools import partial\n",
    "\n",
    "print(\"PyTorch version {}\".format(torch.__version__))\n",
    "print(\"PyG version {}\".format(torch_geometric.__version__))\n",
    "print(\"e3nn version {}\".format(e3nn.__version__))\n",
    "\n",
    "from src.utils.plot_utils import plot_2d, plot_3d\n",
    "from src.utils.train_utils import run_experiment\n",
    "from src.models import MACEModel\n",
    "from cartesian_mace.models.model import CartesianMACE\n",
    "\n",
    "from typing import List\n",
    "import string\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "# print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "# print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "def create_rotsym_envs(fold=3):\n",
    "    dataset = []\n",
    "\n",
    "    # Environment 0\n",
    "    atoms = torch.LongTensor([ 0 ] + [ 0 ] * fold)\n",
    "    edge_index = torch.LongTensor( [ [0] * fold, [i for i in range(1, fold+1)] ] )\n",
    "    x = torch.Tensor([1,0,0])\n",
    "    pos = [\n",
    "        torch.Tensor([0,0,0]),  # origin\n",
    "        x,   # first spoke\n",
    "    ]\n",
    "    for count in range(1, fold):\n",
    "        R = o3.matrix_z(torch.Tensor([2*math.pi/fold * count])).squeeze(0)\n",
    "        pos.append(x @ R.T)\n",
    "    pos = torch.stack(pos)\n",
    "    y = torch.LongTensor([0])  # Label 0\n",
    "    data1 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y)\n",
    "    data1.edge_index = to_undirected(data1.edge_index)\n",
    "    dataset.append(data1)\n",
    "\n",
    "    # Environment 1\n",
    "    q = 2*math.pi/(fold + random.randint(1, fold))\n",
    "    assert q < 2*math.pi/fold\n",
    "    Q = o3.matrix_z(torch.Tensor([q])).squeeze(0)\n",
    "    pos = pos @ Q.T\n",
    "    y = torch.LongTensor([1])  # Label 1\n",
    "    data2 = Data(atoms=atoms, edge_index=edge_index, pos=pos, y=y)\n",
    "    data2.edge_index = to_undirected(data2.edge_index)\n",
    "    dataset.append(data2)\n",
    "\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harryshaw/PycharmProjects/geometric-gnn-dojo/venv/lib/python3.9/site-packages/torch/jit/_check.py:181: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\"The TorchScript type system doesn't support \"\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "correlation = 2\n",
    "max_ell = 3\n",
    "fold = 2\n",
    "\n",
    "# Create dataset\n",
    "dataset = create_rotsym_envs(fold)\n",
    "# for data in dataset:\n",
    "    # plot_2d(data, lim=1)\n",
    "\n",
    "# Create dataloaders\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "n_layers = 1\n",
    "\n",
    "cmace_model = CartesianMACE(n_layers=n_layers, dim=3, n_channels=3, self_tp_rank_max=max_ell, basis_rank_max=max_ell, feature_rank_max=max_ell, nu_max=correlation)\n",
    "\n",
    "mace_model = MACEModel(scalar_pred=False, correlation=correlation, num_layers=n_layers, out_dim=2, max_ell=max_ell, emb_dim=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for MACEModel (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 2 runs: \n",
      " - Training time: 1.83s ± 0.07. \n",
      " - Best validation accuracy: 75.000 ± 25.000. \n",
      "- Test accuracy: 75.0 ± 25.0. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc, test_acc, train_time = run_experiment(\n",
    "    mace_model,\n",
    "    dataloader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100,\n",
    "    n_times=2,\n",
    "    device=device,\n",
    "    verbose=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "data": {
      "text/plain": "100.0"
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.utils.train_utils import eval\n",
    "from torch.nn.functional import cross_entropy, softmax\n",
    "eval(mace_model, val_loader, 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n6/k7q2_21s0hg6l8hvv7cjnrh00000gn/T/ipykernel_96726/1476485892.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax(torch.Tensor([-0.5387, -1.2]))\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0.6596, 0.3404])"
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(torch.Tensor([-0.5387, -1.2]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor(0.5032, grad_fn=<NllLossBackward0>)\n",
      "tensor([[ 0.2055, -0.2191]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1])\n",
      "tensor(0.5417, grad_fn=<NllLossBackward0>)\n",
      "tensor([[0.0409, 0.3710]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in val_loader:\n",
    "    print(batch.y)\n",
    "    print(cross_entropy(mace_model(batch), batch.y))\n",
    "    print(mace_model(batch))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "def linearise_features(h: List[torch.Tensor]) -> torch.Tensor:\n",
    "    # i from 0 to feature_rank_max e.g. for feature_rank_max = 2\n",
    "    # in: list with h[i] = [ [n_nodes, n_channels, 1], [n_nodes, n_channels, 2], [n_nodes, n_channels, 2, 2] ]\n",
    "    # out: [n_nodes, (1 * n_channels) + (2 * n_channels) + (2 * 2 * n_channels)]\n",
    "    # we do this such that we have n_channel lots of each feature in order then the next\n",
    "\n",
    "    h_flattened = []\n",
    "\n",
    "    # essentially need to flatten all the dimensions\n",
    "    for h_i in h:\n",
    "\n",
    "        h_flattened.append(\n",
    "            h_i.flatten(start_dim=1, end_dim=-1)\n",
    "        )\n",
    "\n",
    "    return torch.cat(h_flattened, dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "def run_cmace_rotsym_test(fold: int, max_ell: int, n_times: int, cmace: bool=True) -> None:\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "\n",
    "    dataset = create_rotsym_envs(fold)\n",
    "    # for data in dataset:\n",
    "        # plot_2d(data, lim=1)\n",
    "\n",
    "    # Create dataloaders\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    val_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    test_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    if cmace:\n",
    "        model = CartesianMACE(n_layers=1, dim=3, n_channels=3, self_tp_rank_max=max_ell, basis_rank_max=max_ell, feature_rank_max=max_ell, nu_max=correlation)\n",
    "    else:\n",
    "        model = MACEModel(scalar_pred=False, correlation=correlation, num_layers=n_layers, out_dim=2, max_ell=max_ell, emb_dim=3)\n",
    "\n",
    "    print(model(list(val_loader)[0]))\n",
    "\n",
    "\n",
    "    best_val_acc, test_acc, train_time = run_experiment(\n",
    "        model,\n",
    "        dataloader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        n_epochs=1000,\n",
    "        n_times=n_times,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 2-fold symmetry:\n",
      "tensor([[ 5.0635, -0.4064]], grad_fn=<AddmmBackward0>)\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:27<00:00, 27.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 27.66s ± 0.00. \n",
      " - Best validation accuracy: 100.000 ± 0.000. \n",
      "- Test accuracy: 100.0 ± 0.0. \n",
      "\n",
      "Testing 3-fold symmetry:\n",
      "tensor([[6.5633, 6.6753]], grad_fn=<AddmmBackward0>)\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:25<00:00, 25.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 25.78s ± 0.00. \n",
      " - Best validation accuracy: 100.000 ± 0.000. \n",
      "- Test accuracy: 100.0 ± 0.0. \n",
      "\n",
      "Testing 5-fold symmetry:\n",
      "tensor([[11.8595, 64.1019]], grad_fn=<AddmmBackward0>)\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:28<00:00, 28.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 28.52s ± 0.00. \n",
      " - Best validation accuracy: 100.000 ± 0.000. \n",
      "- Test accuracy: 100.0 ± 0.0. \n",
      "\n",
      "Testing 10-fold symmetry:\n",
      "tensor([[-1049.5126,   812.5063]], grad_fn=<AddmmBackward0>)\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:29<00:00, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 29.19s ± 0.00. \n",
      " - Best validation accuracy: 100.000 ± 0.000. \n",
      "- Test accuracy: 100.0 ± 0.0. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in [2,3,5,10]:\n",
    "    print(f'Testing {fold}-fold symmetry:')\n",
    "\n",
    "    run_cmace_rotsym_test(fold=fold, max_ell=2, n_times=1, cmace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 2-fold symmetry:\n",
      "tensor([[ 1.3711e+09, -4.8328e+08]], grad_fn=<AddmmBackward0>)\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:22<00:00, 142.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 142.57s ± 0.00. \n",
      " - Best validation accuracy: 100.000 ± 0.000. \n",
      "- Test accuracy: 100.0 ± 0.0. \n",
      "\n",
      "Testing 3-fold symmetry:\n",
      "tensor([[ 9.8248e+08, -5.4012e+09]], grad_fn=<AddmmBackward0>)\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:50<00:00, 110.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 110.14s ± 0.00. \n",
      " - Best validation accuracy: 100.000 ± 0.000. \n",
      "- Test accuracy: 100.0 ± 0.0. \n",
      "\n",
      "Testing 5-fold symmetry:\n",
      "tensor([[-5.0708e+09, -3.2243e+10]], grad_fn=<AddmmBackward0>)\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:03<00:00, 123.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 123.67s ± 0.00. \n",
      " - Best validation accuracy: 50.000 ± 0.000. \n",
      "- Test accuracy: 50.0 ± 0.0. \n",
      "\n",
      "Testing 10-fold symmetry:\n",
      "tensor([[ 4.7400e+11, -2.8252e+11]], grad_fn=<AddmmBackward0>)\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:26<00:00, 146.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 146.97s ± 0.00. \n",
      " - Best validation accuracy: 100.000 ± 0.000. \n",
      "- Test accuracy: 100.0 ± 0.0. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in [2,3,5,10]:\n",
    "    print(f'Testing {fold}-fold symmetry:')\n",
    "\n",
    "    run_cmace_rotsym_test(fold=fold, max_ell=3, n_times=1, cmace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "def model_var(n: int, cmace: Optional[bool] = True) -> torch.Tensor:\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for _ in range(n):\n",
    "\n",
    "        if cmace:\n",
    "            model = CartesianMACE(n_layers=1, dim=3, n_channels=3, self_tp_rank_max=max_ell, basis_rank_max=1, feature_rank_max=1, nu_max=correlation)\n",
    "        else:\n",
    "            model = MACEModel(scalar_pred=False, correlation=correlation, num_layers=n_layers, out_dim=2, max_ell=max_ell, emb_dim=3)\n",
    "\n",
    "\n",
    "        for batch in val_loader:\n",
    "            results.append(\n",
    "                model(batch)\n",
    "            )\n",
    "\n",
    "    results = [torch.abs(t) for t in results]\n",
    "\n",
    "    # Sum the absolute values\n",
    "    results = sum([torch.sum(t) for t in results])\n",
    "\n",
    "    return results/(2*n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(22.8486, grad_fn=<DivBackward0>),\n tensor(0.9643, grad_fn=<DivBackward0>))"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_var(100, cmace=True), model_var(100, cmace=False) # look at the difference - not good!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0:\n",
      "\n",
      "tensor([[21.8927, 31.9994]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[17.0885, 32.3366]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "1:\n",
      "\n",
      "tensor([[-3.1212,  2.2876]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.1207,  2.3620]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "2:\n",
      "\n",
      "tensor([[3.5849, 1.4479]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[3.2797, 1.6850]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "3:\n",
      "\n",
      "tensor([[-0.6088, -0.3887]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.4987, -0.6045]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "4:\n",
      "\n",
      "tensor([[-17.1576,  13.1661]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-5.8083,  1.3818]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "5:\n",
      "\n",
      "tensor([[-5.8845,  5.2995]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-5.6594,  4.0376]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "6:\n",
      "\n",
      "tensor([[-14.7398, -10.2856]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.9204, 3.1388]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "7:\n",
      "\n",
      "tensor([[-10.7634,  10.7773]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-14.2322,   3.7056]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "8:\n",
      "\n",
      "tensor([[-5.3279, -2.0156]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-6.2400, -1.4088]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "9:\n",
      "\n",
      "tensor([[-16.9670,  -5.0818]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-17.3763,  -7.9819]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "10:\n",
      "\n",
      "tensor([[-3.0625, -3.0781]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-5.7783, -0.6492]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "11:\n",
      "\n",
      "tensor([[31.4983,  2.5629]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[18.5321, -2.9624]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "12:\n",
      "\n",
      "tensor([[ 17.8124, -10.6298]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 18.3742, -10.0270]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "13:\n",
      "\n",
      "tensor([[-30.4009,   7.5961]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-30.6561,   6.6944]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "14:\n",
      "\n",
      "tensor([[ 4.3090, -1.0489]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 4.0714, -1.4333]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "15:\n",
      "\n",
      "tensor([[-13.5978, -16.0575]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-14.9797, -14.9429]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "16:\n",
      "\n",
      "tensor([[0.1384, 0.3641]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-3.4193, -1.5244]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "17:\n",
      "\n",
      "tensor([[-6.5717, -0.8992]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-2.5480, -2.6924]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "18:\n",
      "\n",
      "tensor([[ 3.9384, -4.3385]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 3.5728, -3.9187]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "19:\n",
      "\n",
      "tensor([[-0.4807,  0.3486]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.4983,  0.4522]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "\n",
    "    torch.manual_seed(i)\n",
    "\n",
    "    cmace = CartesianMACE(n_layers=1, dim=3, n_channels=3, self_tp_rank_max=max_ell, basis_rank_max=1, feature_rank_max=1, nu_max=correlation)\n",
    "\n",
    "    # mace = MACEModel(scalar_pred=False, correlation=correlation, num_layers=n_layers, out_dim=2, max_ell=max_ell, emb_dim=3)\n",
    "\n",
    "    # cmace.apply(he_init)\n",
    "\n",
    "    print(f'\\n\\n{i}:\\n')\n",
    "    for batch in val_loader:\n",
    "        print(cmace(batch))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 2-fold symmetry:\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 7.92s ± 0.00. \n",
      " - Best validation accuracy: 100.000 ± 0.000. \n",
      "- Test accuracy: 100.0 ± 0.0. \n",
      "\n",
      "Testing 3-fold symmetry:\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 8.24s ± 0.00. \n",
      " - Best validation accuracy: 50.000 ± 0.000. \n",
      "- Test accuracy: 50.0 ± 0.0. \n",
      "\n",
      "Testing 5-fold symmetry:\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 8.45s ± 0.00. \n",
      " - Best validation accuracy: 50.000 ± 0.000. \n",
      "- Test accuracy: 50.0 ± 0.0. \n",
      "\n",
      "Testing 10-fold symmetry:\n",
      "Running experiment for CartesianMACE (cpu).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done! Averaged over 1 runs: \n",
      " - Training time: 8.22s ± 0.00. \n",
      " - Best validation accuracy: 50.000 ± 0.000. \n",
      "- Test accuracy: 50.0 ± 0.0. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(19)\n",
    "cmace = CartesianMACE(n_layers=1, dim=3, n_channels=3, self_tp_rank_max=max_ell, basis_rank_max=1, feature_rank_max=1, nu_max=correlation)\n",
    "\n",
    "for fold in [2,3,5,10]:\n",
    "    print(f'Testing {fold}-fold symmetry:')\n",
    "\n",
    "    run_cmace_rotsym_test(fold=fold, max_ell=3, n_times=1, cmace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.9854e-01, -3.5726e-01, -3.9072e-01],\n",
      "         [-3.2756e-01, -3.3672e-01,  5.4324e-02],\n",
      "         [-4.7563e-01, -3.6555e-01, -1.9465e-01]],\n",
      "\n",
      "        [[ 2.6603e-01,  6.9126e-02,  2.4355e-02],\n",
      "         [-5.6519e-02, -3.9547e-01,  5.3077e-02],\n",
      "         [ 5.7877e-01, -2.4843e-01, -6.0395e-01]],\n",
      "\n",
      "        [[-1.5657e-01, -3.3078e-02, -1.4469e-01],\n",
      "         [ 3.5730e-01,  4.2795e-01,  3.7995e-01],\n",
      "         [ 6.7736e-02, -6.4437e-01, -2.7703e-02]],\n",
      "\n",
      "        [[ 1.9814e-01, -6.4704e-01,  2.6346e-01],\n",
      "         [ 1.4470e-01,  4.3917e-01, -1.6734e-01],\n",
      "         [-7.4332e-02,  1.2774e-01, -4.1656e-01]],\n",
      "\n",
      "        [[ 2.6841e-01, -7.5766e-02, -3.0645e-01],\n",
      "         [ 5.1275e-01, -1.6116e-01,  3.7877e-01],\n",
      "         [ 8.4154e-02,  1.6264e-01,  1.9937e-01]],\n",
      "\n",
      "        [[ 7.3956e-01, -1.7768e-01, -2.0547e-01],\n",
      "         [-5.9323e-02, -1.0115e-01,  7.6055e-02],\n",
      "         [-2.3259e-01,  2.0006e-02,  1.4674e-01]],\n",
      "\n",
      "        [[ 1.5771e-01,  5.7383e-01, -6.3143e-02],\n",
      "         [-3.7634e-02,  2.6043e-01,  2.5316e-01],\n",
      "         [-4.4798e-01,  1.7820e-01, -5.1521e-01]],\n",
      "\n",
      "        [[-3.0277e-01, -2.0533e-01,  3.9243e-01],\n",
      "         [ 2.3221e-01, -4.0109e-01,  5.0053e-01],\n",
      "         [-1.8605e-01,  2.8350e-01, -1.4965e-01]],\n",
      "\n",
      "        [[-2.8775e-01, -5.6089e-02, -6.3542e-01],\n",
      "         [ 3.1274e-01, -4.0769e-04, -3.0627e-01],\n",
      "         [ 9.9488e-02,  3.6765e-01, -2.6925e-01]],\n",
      "\n",
      "        [[-8.7770e-02, -1.8956e-01, -2.4192e-01],\n",
      "         [-5.6686e-01,  2.9884e-01,  5.1401e-01],\n",
      "         [ 3.4973e-01,  3.1460e-01,  3.8234e-02]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the dimensions of the matrix\n",
    "n = 3\n",
    "\n",
    "# Create an empty tensor of the desired size\n",
    "orthogonal_matrix = torch.empty(10, n, n)\n",
    "\n",
    "# Initialize the tensor with a random orthogonal matrix\n",
    "torch.nn.init.orthogonal_(orthogonal_matrix)\n",
    "\n",
    "print(orthogonal_matrix)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.0000, grad_fn=<DotBackward0>)"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_weights = nn.Parameter(data=torch.randn(4, 4))\n",
    "channel_weights = torch.nn.init.orthogonal_(channel_weights)\n",
    "\n",
    "channel_weights[0] @ channel_weights[0].T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.0000e+00, -1.7393e-08, -7.4113e-08, -4.7840e-09],\n        [-1.7393e-08,  1.0000e+00, -5.9454e-08, -5.3868e-08],\n        [-7.4113e-08, -5.9454e-08,  1.0000e+00,  1.1606e-07],\n        [-4.7840e-09, -5.3868e-08,  1.1606e-07,  1.0000e+00]],\n       grad_fn=<MmBackward0>)"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_weights @ channel_weights.T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[[ 0.8572, -0.0587],\n         [-0.5013, -0.1021]],\n\n        [[ 0.2161,  0.5237],\n         [ 0.4490, -0.6910]],\n\n        [[ 0.1597, -0.8346],\n         [ 0.4323, -0.3017]]], requires_grad=True)"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_weights = nn.Parameter(data=torch.randn(3, 2, 2))\n",
    "channel_weights = torch.nn.init.orthogonal_(channel_weights)\n",
    "\n",
    "# torch.nn.utils.parametrizations.orthogonal(channel_weights)\n",
    "channel_weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[ 0.7383, -0.4237],\n         [-0.4237,  0.2617]], grad_fn=<MmBackward0>),\n tensor([[ 0.3210, -0.2648],\n         [-0.2648,  0.6790]], grad_fn=<MmBackward0>),\n tensor([[0.7221, 0.3209],\n         [0.3209, 0.2779]], grad_fn=<MmBackward0>)]"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[Q @ Q.T for Q in channel_weights]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "from scipy.stats import ortho_group\n",
    "x = torch.from_numpy(ortho_group.rvs(3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1.0000e+00,  0.0000e+00,  1.2490e-16],\n        [ 0.0000e+00,  1.0000e+00, -2.7756e-17],\n        [ 1.2490e-16, -2.7756e-17,  1.0000e+00]], dtype=torch.float64)"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-1.3964, -0.2122, -0.9179],\n        [ 0.9133,  0.5158, -0.7792],\n        [ 0.0905, -0.6632,  1.7903],\n        [-0.5818, -0.6062, -0.2633],\n        [ 0.3076, -0.5345, -0.0529],\n        [-2.6448,  1.7043, -0.1977],\n        [-0.5439,  1.5979, -0.0913],\n        [ 0.2242,  0.0512, -1.8578],\n        [-0.2327,  1.9302, -0.7186],\n        [-0.2226,  0.4280,  0.8668]])"
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.randn(10, 3) # paths x channels\n",
    "weights /= weights.std(dim=0)\n",
    "\n",
    "weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(2.8319)"
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 3)\n",
    "\n",
    "sum(x[:,0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.1466, 1.0878, 0.6871])"
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.std(dim=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
